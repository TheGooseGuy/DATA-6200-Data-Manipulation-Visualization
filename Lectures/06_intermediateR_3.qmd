---
title: "Intermediate R programming Concepts part 3"
author: "DATA*6200"
date: "Sept 25, 2024"
format: 
  revealjs:
    echo: true
    code-line-numbers: false
    slide-number: true
---

## Learning objectives and reading

::: columns
::: {.column width="50%"}
-   Finishing up joins

-   Date variables

-   Quick notes on Missingness
:::


::: {.column width="50%"}
Reading: R for Data Science, Chapters 17,18,19

```{r, results=  'hide'}
library(tidyverse)
library(nycflights13)
library(babynames)
```
:::

:::

# Joins (recap)

```{r}
library(nycflights13)
```

## Keys

Challenging data projects often involve multiple tables. These tables can be **joined** together based on **keys**, which are variable(s) that are in common between data sets.

. . .


For instance, consider the data sets:

::: columns
::: {.column width="45%"}
```{r}
airlines |> head()
```
:::

::: {.column width="55%"}
```{r}
airports |> select(faa, lat, lon) |> head()
```
:::
:::

## Primary and compound keys

A **primary key** is/are variable(s) that uniquely identify each observation. If more than one variable is needed to uniquely identify the row, then it is known as a **compound key**.

. . .


In the airlines data set, either variable could identify each row, the `carrier` variable is succinct and precise.

. . .


```{r}
airlines |> head()
```

## Primary and compound keys (contd.)

In this weather data, what is needed to identify each row. I.e, what is the key?

. . .


```{r}
weather_keyinfo <- weather |> select(origin, time_hour, temp, wind_speed) 
weather_keyinfo
```

## Foreign keys

A foreign key is a set of variables corresponding to the primary key of another dataset. e.g `carrier` is a variable in `flights`, and it is the primary key in

. . .


But it certainly doesn't uniquely identify each observation (which columns do?).

::: columns
::: {.column width="60%"}
`flights`

```{r, echo = FALSE}
flights_keyinfo <- flights |> 
  select(carrier, flight, time_hour, origin, dest) |> 
  head()
flights_keyinfo
```
:::

::: {.column width="40%"}
`airlines`

```{r, echo = FALSE}
airlines |> head()
```
:::
:::

## Joins

If you are familiar with SQL, you have probably used joins before. Joins allow you to combine information from data frames using their keys.

. . .


Dplyr has \~6 functions that allow for joining. The most common is the `left_join()`.

. . .


```{r}
flights_keyinfo |> 
  left_join(airlines, by = c("carrier"))
```

## Joins (cont.)

What if we wanted the weather information from the `weather` data frame?

. . .


```{r}
flights_keyinfo |> 
  left_join(weather_keyinfo, by = c("time_hour", "origin")) 
```

. . .


By default, by = all columns in common. I would rarely leave this argument empty.

## Joining on non-equal column names

A couple of slides ago, we joined on carrier:

. . .


```{.r}
flights_keyinfo |> 
  left_join(airlines, by = c("carrier"))
```

. . .


This is equivalent to:

. . .


```{.r}
flights_keyinfo |> 
  left_join(airlines, join_by(carrier == carrier))
```

. . .


Or you can use the names of the columns:

. . .


``` r
flights_keyinfo |> 
  left_join(airlines, by = c("carrier" = "carrier"))
```

## Joining on non-equal column names

If the names are non-equal, we can use the notation:

. . .


```{r}
flights_keyinfo |> 
  left_join(airports, join_by(dest == faa))
```

. . .


That is, the column is named `dest` in `flights` and `faa` in airports.

## Multiple matches

If we `left_join(x,y)`, then the result will have at least as many rows as table `x`. If there is more than 1 row in `y` that matches the key in `x`, it will output 1 row for each.

. . .


If there are 0 rows in `y` that have a matching key to a row in `x`, the corresponding row in `x` will have an NA.

. . .


::: columns
::: {.column width="33%"}
df1

```{r, echo = FALSE}
df1 <- tibble(key = c(1, 2, 3, 3), val_x = c("x1", "x2", "x3","x4"))
print(df1, row.names = FALSE)
```
:::

::: {.column width="33%"}
df2

```{r, echo = FALSE}
df2 <- tibble(key = c(1, 2, 2, 4), val_y = c("y1", "y2", "y3","y4"))
print(df2, row.names = FALSE)
```
:::

::: {.column width="33%"}
```{r}
left_join(df1, df2)
```
:::
:::

## Other joins

**Right joins** are the same idea, just reverse the roles of x and y.

. . .


**Inner joins** return only the rows that are in common between them. **Full Joins** return all rows.

. . .


::: columns
::: {.column width="50%"}
Inner joins

```{r}
inner_join(df1,df2)
```
:::

::: {.column width="50%"}
Full join

```{r}
full_join(df1,df2)
```
:::
:::


## Cross-joins

Cross joins return 1 row for every permutation of two keys.

```{r}
letters <- data.frame(letters = c("a", "b", "c"))
numbers <- data.frame(numbers = c(1,2,3))

cross_join(letters,numbers)

```


## Inequality joins

We can also join based on relationships. E.g `<`, `<=`, `>=`, `>`.

. . .

```{r}
df <- data.frame(letters, numbers)

df |> left_join(df, join_by(numbers<numbers))
```

## Exercise

Join the latitude and longitude variables from `airports` to `flights` for both the origin **and** destination airports.

What happens to the names of variables?

# Date variables

Tibbles have three types of date/time variables: **date**, **time**, and **date-time**.

**POSIX calendar time** aka POSIXct is the number of seconds since 1970 in the GMT timezone. 

R also has a class called **POSIXlt** where lt stands for local time. These are base-R things.

. . .

Tibbles calls these `<dttm>`.

. . .

`Lubridate` has functions that make working with dates easy.

```{r}
today()
now("GMT")
now()
```
## ISO8601

**ISO8601** is a standard date format. E.g September 16, 1992 is `1992-09-16`. 

. . .

Can add times using `1992-09-16 08:21:57` where it goes from "biggest to smallest", year-month-day hours:mins:secs.

. . .

If you load a date into R with this format, it will just work.

. . .

```{r}
csv <- "
  date,datetime
  2022-01-02,2022-01-02 05:12
"
read_csv(csv)
```

## Non-standard data import

Non-standard dates can be misinterpretted:

. . .

```{r}
csv <- "
  date
  01/02/15
"
read_csv(csv, col_types = cols(date = col_date("%m/%d/%y")))
```

. . . 

```{r}
read_csv(csv, col_types = cols(date = col_date("%d/%m/%y")))
```

. . .

```{r}
read_csv(csv, col_types = cols(date = col_date("%y/%m/%d")))
```

## %Y %y %m %b %B

A percent sign, followed by a lower case or capital letter mean different things.

. . .

Examples: 

- `%Y` means treat the date as 4 character year. 
- `%b` recognizes 3-letter abbreviations of months.

. . .

```{r}
csv <- "
  date
  01/Feb/2015
"
read_csv(csv, col_types = cols(date = col_date("%e/%b/%Y")))

```

## Lubridate's automatic date determination

```{r}
dmy("01/Feb/2015") # day month year
```

. . .

```{r}
dmy_hms("01/Feb/2015 14:12:56")
```

These are nice because we can generally ignore the nuisances of parsing dates. E.g 02 vs 2, / vs. -, etc.

## From multiple columns

We can use the `make_datetime` function to make a date column within a data frame.

. . .

```{r}
flights |> 
  select(year, month, day, hour, minute) |> 
  mutate(departure = make_datetime(year, month, day, hour, minute))
```

## From multiple columns (contd.)

The flights data set is a bit messier

. . .

```{r}
flights |> select(year, month, day, dep_time) |> head(5)
```

. . .

It's obvious that 517 means 5:17am. But how to parse? Could use regexp, but that seems like overkill.

. . .

Can pull the 5 out using `%/%` which returns the remainder on the left after dividing by the number on the right.

```{r}
517 %/% 100
```
. . .

We can pull the 17 out using **modulus** which is `%%` in R.

```{r}
517 %% 100
```

## From Multiple Columns (contd.)

```{r}
flights |>
  select(year, month, day,dep_time) |> 
  filter(!is.na(dep_time)) |> 
  mutate(
    dep_time = make_datetime(year, month, day, dep_time %/%100, dep_time%%100 )
  )
```

## Time intervals and durations

How old is Justin:

```{r}
justin_age <- today() - ymd("1992-09-16")
```

. . .

This allows for operations on multiple dates. But...

. . .
```{r}
one_am <- ymd_hms("2026-03-08 01:00:00", tz = "America/New_York")

one_am
one_am + ddays(1)
```

. . .

There are many complications that can happen with dates, because time zones change, not all months are the same length, etc.

# Missing Values

## Missing Values

Missing data in R is represented by `NA` or `NaN` in the cell that they are missing.

. . .

`NA` is the most common. `NaN` will pop up if you do a math calculation that is not well defined.

. . .

If you try to perform an operation on a vector that contains a missing value, it will return NA, even if it is only 1 value.

. . .

```{r}
this <- c(1,2,NA,4)
sum(this)
sum(this, na.rm = TRUE) # use this to ignore NA's.
```

## Not all NA's are equal

Although all NA's have the same value in R, that doesn't mean they are the same in context. Sometimes values are missing but they don't have the value NA.

. . .

A very common question I get when talking about missing data is: 

. . .


- Should I exclude these rows with missing values?
- How should I impute my missing values?

. . .


The answer is not simple. You need to ask yourself why the missing values happened.

## Not all NA's are equal

For instance, suppose you loaded some data into R and found this:

. . .


```{r}
csv <- "
  name,num_cats
  John,1
  Justin,2
  Jason,
  Jill,1
"
read_csv(csv)
```

. . .


Why might there be a missing value here?

## Used car

What about in this example?

. . .


```{r}
csv <- "
  car_make,year, miles 
  Toyota Matrix,2005,60000
  Honda Civic,2011,250000
  Nissan Sentra,2010,100000
  Nissan Altima,2006,0
"
read_csv(csv)
```

## Missingness

My general advice is that data is very valuable, and that you should be very careful about excluding missing values.

. . .

You should look into the potential reason for the missingness through data exploration.

. . .

Account for missingness in modelling if/when possible. E.g if there is a substantial number of missing values in a categorical variable, then treating the NA's as their own category can be helpful.






